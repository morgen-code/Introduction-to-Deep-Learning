# 機械学習入門ノートブックまとめ

このノートブックでは、**機械学習の基礎的な考え方**を段階的に理解するための内容を扱っています。  
単純な**パーセプトロン**から始まり、**活性化関数**、**非線形問題（XOR）**、**応用モデル（じゃんけんや画像認識）**へと発展していきます。

---

## perceptron

### 概要
**パーセプトロン（Perceptron）** は、最も基本的な人工ニューラルネットワークの構成要素です。  
生物学的な神経細胞を模した**単一の線形分類モデル**であり、入力の重み付き和に基づいて出力（0または1）を決定します。

### 得られる理解
- 機械学習の「**教師あり学習**」の基本構造。
- パーセプトロンが「**線形分離しかできない**」という制約。

## activation_function

### 概要
**活性化関数（Activation Function）** は、ニューロンの出力に非線形性を導入するための関数です。  
これにより、モデルはより複雑なパターンを学習できるようになります。

### 内容
- 以下の代表的な活性化関数を**グラフで可視化**：
  - ステップ関数
  - シグモイド関数
  - tanh（双曲線正接）関数
  - ReLU（Rectified Linear Unit）
- 各関数の**勾配**の比較。

### ポイント
- 活性化関数が「学習の表現力」を高める理由。
- 勾配消失問題（Gradient Vanishing）の直感的理解。

## xor_model

### 概要
**XOR（排他的論理和）問題**は、パーセプトロンでは解けない典型的な非線形問題です。  
ここではTensorFlowを用いて、**多層パーセプトロン（MLP）** で解く手法を実装しています。

### 内容
- XORの入出力データセットを生成。
- TensorFlow/Kerasを使用して2層のネットワークを構築。
- 学習曲線（loss, accuracy）を可視化して学習の様子を確認。
- 学習済みモデルによる**予測結果を可視化**。

### ポイント
- 多層化と活性化関数の導入により非線形問題を解けるようになる。
- **ニューラルネットの本質は「特徴変換」**にあることを体感できる。


## janken_model

### 概要
「**じゃんけんの勝敗予測**」という身近な題材を使い、  
分類問題の実践的な流れを体験します。

### 内容
- 手（グー・チョキ・パー）を数値化して入力データを作成。
- モデルを構築し、**プレイヤーの手と相手の手から勝敗を予測**。
- 精度や混同行列を使って結果を分析。

### ポイント
- データの**前処理（エンコーディング）**の重要性。
- モデルが「パターンを学ぶ」とはどういうことか。
- 過学習（overfitting）の兆候や対策の初歩。

## image_recognition_model

### 概要
**MNIST（手書き数字データセット）**を用いた、  
画像認識の基本モデル（ニューラルネットワーク）を構築します。

### 内容
- TensorFlow/Keras によるネットワーク設計。
- 訓練データ（60,000枚）とテストデータ（10,000枚）で学習・評価。
- 精度・損失の推移を可視化。
- 実際の手書き数字画像に対して**予測結果を表示**。

### ポイント
- 画像認識におけるCNNの効果。

## 推奨ステップ

| 段階 | ノートブック | 学習テーマ |
|:--:|:--|:--|
| 1 | perceptron | 線形分類の基礎 |
| 2 | activation_function | 非線形性の導入 |
| 3 | xor_model | 多層構造の意義 |
| 4 | janken_model | 応用的な分類問題 |
| 5 | image_recognition_model | 実データによる画像認識 |

## 実行環境

- Python 3
- JupyterLab、Jupyter Notebook、Google Colaab
- TensorFlow / Keras  
- NumPy, Matplotlib などの標準的なライブラリ  